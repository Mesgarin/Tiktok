{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617c5c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV ...\n",
      "âœ… ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§: 905\n",
      "ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Sentiment Ùˆ Emotion (Ø¨Ø§Ø± Ø§ÙˆÙ„ Ú©Ù…ÛŒ Ø·ÙˆÙ„ Ù…ÛŒâ€ŒÚ©Ø´Ù‡)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NaMe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\NaMe\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n",
      "c:\\Users\\NaMe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\NaMe\\.cache\\huggingface\\hub\\models--j-hartmann--emotion-english-distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n",
      "c:\\Users\\NaMe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ú©Ù¾Ø´Ù†â€ŒÙ‡Ø§ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 905/905 [01:59<00:00,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯: C:/Users/NaMe/OneDrive - Constructor University/Documents/PhD/Tiktok/Tiktok/Data/tiktok_with_sentiment.csv\n",
      "âœ… ØªÙ…Ø§Ù… Ø´Ø¯! Ø­Ø§Ù„Ø§ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø±Ø§ Ø¯Ø± Excel / SPSS / Python ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# 1) ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡\n",
    "# -----------------------------\n",
    "\n",
    "# Ù†Ø§Ù… ÙØ§ÛŒÙ„ CSV Ø§ØµÙ„ÛŒ (Ø®Ø±ÙˆØ¬ÛŒ Apify)\n",
    "INPUT_CSV = \"C:/Users/NaMe/OneDrive - Constructor University/Documents/PhD/Tiktok/Tiktok/Data/tiktok.csv\"          # Ø§Ú¯Ø± Ø§Ø³Ù… ÙØ§ÛŒÙ„ ØªÙˆ Ú†ÛŒØ² Ø¯ÛŒÚ¯Ù‡â€ŒØ§ÛŒÙ‡ØŒ Ù‡Ù…ÛŒÙ†Ø¬Ø§ Ø¹ÙˆØ¶Ø´ Ú©Ù†\n",
    "OUTPUT_CSV = \"C:/Users/NaMe/OneDrive - Constructor University/Documents/PhD/Tiktok/Tiktok/Data/tiktok_with_sentiment.csv\"\n",
    "\n",
    "# Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù…ØªÙ† Ú©Ù‡ Ø¨Ù‡ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØ¯ÛŒÙ… (Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø®ÛŒÙ„ÛŒ Ø¨Ù„Ù†Ø¯ Ù†Ø¨Ø§Ø´Ù‡)\n",
    "MAX_TEXT_LEN = 256\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV\n",
    "# -----------------------------\n",
    "print(\"ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV ...\")\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Ú†Ú© Ú©Ù†ÛŒÙ… Ø³ØªÙˆÙ† 'text' ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡\n",
    "if \"text\" not in df.columns:\n",
    "    raise ValueError(\"Ø³ØªÙˆÙ† 'text' Ø¯Ø± ÙØ§ÛŒÙ„ CSV Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ù†Ø§Ù… Ø³ØªÙˆÙ† Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ 'text' Ø§Ø³Øª.\")\n",
    "\n",
    "print(f\"âœ… ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§: {len(df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
    "# -----------------------------\n",
    "print(\"ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Sentiment Ùˆ Emotion (Ø¨Ø§Ø± Ø§ÙˆÙ„ Ú©Ù…ÛŒ Ø·ÙˆÙ„ Ù…ÛŒâ€ŒÚ©Ø´Ù‡)...\")\n",
    "\n",
    "# Ù…Ø¯Ù„ Ø§Ø­Ø³Ø§Ø³ Ù…Ø«Ø¨Øª/Ù…Ù†ÙÛŒ/Ø®Ù†Ø«ÛŒ\n",
    "sentiment_model = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")\n",
    "\n",
    "# Ù…Ø¯Ù„ Emotion (joy, anger, sadness, fear, ...)\n",
    "emotion_model = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    return_all_scores=False\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ\n",
    "# -----------------------------\n",
    "def clean_text(text):\n",
    "    \"\"\"ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø§Ø³ØªØ±ÛŒÙ†Ú¯ØŒ Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ØŒ Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ø·ÙˆÙ„Ø§Ù†ÛŒ\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    if len(text) > MAX_TEXT_LEN:\n",
    "        text = text[:MAX_TEXT_LEN]\n",
    "    return text\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    text = clean_text(text)\n",
    "    if text == \"\":\n",
    "        return None, None\n",
    "    try:\n",
    "        result = sentiment_model(text)[0]\n",
    "        label = result[\"label\"]      # Ù…Ø«Ù„Ø§: \"Positive\" / \"Negative\" / \"Neutral\"\n",
    "        score = float(result[\"score\"])\n",
    "        return label, score\n",
    "    except Exception as e:\n",
    "        print(\"Ø®Ø·Ø§ Ø¯Ø± sentiment:\", e)\n",
    "        return None, None\n",
    "\n",
    "def analyze_emotion(text):\n",
    "    text = clean_text(text)\n",
    "    if text == \"\":\n",
    "        return None, None\n",
    "    try:\n",
    "        result = emotion_model(text)[0]\n",
    "        label = result[\"label\"]      # Ù…Ø«Ù„Ø§: \"joy\", \"anger\", \"sadness\", ...\n",
    "        score = float(result[\"score\"])\n",
    "        return label, score\n",
    "    except Exception as e:\n",
    "        print(\"Ø®Ø·Ø§ Ø¯Ø± emotion:\", e)\n",
    "        return None, None\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÛŒ Ù‡Ù…Ù‡ Ú©Ù¾Ø´Ù†â€ŒÙ‡Ø§\n",
    "# -----------------------------\n",
    "sentiment_labels = []\n",
    "sentiment_scores = []\n",
    "emotion_labels = []\n",
    "emotion_scores = []\n",
    "\n",
    "print(\"ğŸ“Š Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ú©Ù¾Ø´Ù†â€ŒÙ‡Ø§ ...\")\n",
    "\n",
    "for text in tqdm(df[\"text\"], total=len(df)):\n",
    "    s_label, s_score = analyze_sentiment(text)\n",
    "    e_label, e_score = analyze_emotion(text)\n",
    "\n",
    "    sentiment_labels.append(s_label)\n",
    "    sentiment_scores.append(s_score)\n",
    "    emotion_labels.append(e_label)\n",
    "    emotion_scores.append(e_score)\n",
    "\n",
    "# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯\n",
    "df[\"sentiment_label\"] = sentiment_labels\n",
    "df[\"sentiment_score\"] = sentiment_scores\n",
    "df[\"emotion_label\"] = emotion_labels\n",
    "df[\"emotion_score\"] = emotion_scores\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡\n",
    "# -----------------------------\n",
    "print(f\"ğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯: {OUTPUT_CSV}\")\n",
    "df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"âœ… ØªÙ…Ø§Ù… Ø´Ø¯! Ø­Ø§Ù„Ø§ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø±Ø§ Ø¯Ø± Excel / SPSS / Python ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d47c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø¯Øª Ø§Ø­Ø³Ø§Ø³: 0.7419687488320407\n",
      "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø¯Øª Emotion: 0.6719238547912827\n",
      "sentiment_label\n",
      "neutral     408\n",
      "negative    355\n",
      "positive    136\n",
      "Name: count, dtype: int64\n",
      "emotion_label\n",
      "fear        424\n",
      "joy         190\n",
      "anger       119\n",
      "neutral     105\n",
      "sadness      27\n",
      "disgust      24\n",
      "surprise     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/NaMe/OneDrive - Constructor University/Documents/PhD/Tiktok/Tiktok/Data/tiktok_with_sentiment.csv\")\n",
    "\n",
    "# Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø¯Øª Ø§Ø­Ø³Ø§Ø³Ø§Øª (Ø§Ø³Ú©ÙˆØ±)\n",
    "mean_sentiment = df[\"sentiment_score\"].mean()\n",
    "mean_emotion = df[\"emotion_score\"].mean()\n",
    "\n",
    "print(\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø¯Øª Ø§Ø­Ø³Ø§Ø³:\", mean_sentiment)\n",
    "print(\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø¯Øª Emotion:\", mean_emotion)\n",
    "\n",
    "# ØªÙˆØ²ÛŒØ¹ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ (Ù…Ø«Ù„Ø§Ù‹ Ú†Ù†Ø¯ØªØ§ Ù…Ø«Ø¨ØªØŸ Ú†Ù†Ø¯ØªØ§ Ù…Ù†ÙÛŒØŸ)\n",
    "print(df[\"sentiment_label\"].value_counts())\n",
    "print(df[\"emotion_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16d4ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sentiment_score  emotion_score  diggCount  commentCount  \\\n",
      "sentiment_score         1.000000       0.014374   0.019371      0.027320   \n",
      "emotion_score           0.014374       1.000000   0.072844      0.064847   \n",
      "diggCount               0.019371       0.072844   1.000000      0.883837   \n",
      "commentCount            0.027320       0.064847   0.883837      1.000000   \n",
      "shareCount              0.024788       0.081119   0.711433      0.621452   \n",
      "playCount               0.038684       0.070256   0.754814      0.582157   \n",
      "\n",
      "                 shareCount  playCount  \n",
      "sentiment_score    0.024788   0.038684  \n",
      "emotion_score      0.081119   0.070256  \n",
      "diggCount          0.711433   0.754814  \n",
      "commentCount       0.621452   0.582157  \n",
      "shareCount         1.000000   0.692124  \n",
      "playCount          0.692124   1.000000  \n"
     ]
    }
   ],
   "source": [
    "corr = df[[\"sentiment_score\", \"emotion_score\", \n",
    "           \"diggCount\", \"commentCount\", \"shareCount\", \"playCount\"]].corr()\n",
    "\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94519347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"engagement\"] = df[\"diggCount\"] + df[\"commentCount\"] + df[\"shareCount\"] + df[\"playCount\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c52a2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/NaMe/OneDrive - Constructor University/Documents/PhD/Tiktok/Tiktok/Data/tiktok_with_sentiment.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6696df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"sentiment_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7241895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diggCount\"] = pd.to_numeric(df[\"diggCount\"], errors=\"coerce\")\n",
    "df[\"commentCount\"] = pd.to_numeric(df[\"commentCount\"], errors=\"coerce\")\n",
    "df[\"shareCount\"] = pd.to_numeric(df[\"shareCount\"], errors=\"coerce\")\n",
    "df[\"playCount\"] = pd.to_numeric(df[\"playCount\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac6fad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0faaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             engagement   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     1.289\n",
      "Date:                Sun, 23 Nov 2025   Prob (F-statistic):              0.257\n",
      "Time:                        12:36:37   Log-Likelihood:                -14972.\n",
      "No. Observations:                 899   AIC:                         2.995e+04\n",
      "Df Residuals:                     897   BIC:                         2.996e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const             1.36e+05   7.28e+05      0.187      0.852   -1.29e+06    1.57e+06\n",
      "sentiment_score  1.094e+06   9.64e+05      1.135      0.257   -7.98e+05    2.99e+06\n",
      "==============================================================================\n",
      "Omnibus:                     1698.481   Durbin-Watson:                   2.040\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1907972.742\n",
      "Skew:                          13.420   Prob(JB):                         0.00\n",
      "Kurtosis:                     227.088   Cond. No.                         10.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1) Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„\n",
    "df = pd.read_csv(\"C:/Users/NaMe/OneDrive - Constructor University/Documents/PhD/Tiktok/Tiktok/Data/tiktok_with_sentiment.csv\")\n",
    "\n",
    "# 2) ØªØ¨Ø¯ÛŒÙ„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "for col in [\"diggCount\", \"commentCount\", \"shareCount\", \"playCount\"]:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# 3) Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø­Ø³Ø§Ø³Ø§ØªØ´Ø§Ù† NA Ø§Ø³Øª\n",
    "df = df.dropna(subset=[\"sentiment_score\"])\n",
    "\n",
    "# 4) Ø³Ø§Ø®Øª Ù…ØªØºÛŒØ± engagement\n",
    "df[\"engagement\"] = df[\"diggCount\"] + df[\"commentCount\"] + df[\"shareCount\"] + df[\"playCount\"]\n",
    "\n",
    "# 5) Ù…Ø¯Ù„ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†\n",
    "X = df[\"sentiment_score\"]\n",
    "y = df[\"engagement\"]\n",
    "\n",
    "X = sm.add_constant(X)   # Ø§Ø¶Ø§ÙÙ‡â€ŒÚ©Ø±Ø¯Ù† b0\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"tiktok_with_sentiment.csv\")\n",
    "\n",
    "# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ numeric\n",
    "for col in [\"diggCount\", \"commentCount\", \"shareCount\", \"playCount\", \"videoMeta.duration\"]:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# ØªØ¹Ø¯Ø§Ø¯ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§\n",
    "df[\"hashtag_count\"] = df[\"text\"].str.count(\"#\")\n",
    "\n",
    "# Ø³Ø§Ø®Øª engagement\n",
    "df[\"engagement\"] = df[\"diggCount\"] + df[\"commentCount\"] + df[\"shareCount\"] + df[\"playCount\"]\n",
    "\n",
    "# Ù…Ø¯Ù„ Ú†Ù†Ø¯Ù…ØªØºÛŒØ±Ù‡\n",
    "X = df[[\n",
    "    \"sentiment_score\",\n",
    "    \"emotion_score\",\n",
    "    \"hashtag_count\",\n",
    "    \"videoMeta.duration\"\n",
    "]]\n",
    "\n",
    "y = df[\"engagement\"]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
